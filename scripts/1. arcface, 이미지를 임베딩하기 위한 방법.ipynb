{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import get_file\n",
    "\n",
    "np.set_printoptions(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 데이터 : MNIST\n",
    "\n",
    "MNIST 숫자는 (28,28)의 크기를 가진 행렬입니다. arcface를 통한 숫자 임베딩해 보도록 하겠습니다. 일반적인 Image Classification 모델에 `ARCFACE`라 불리는 Layer를 추가하는 것이 특징입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "trainset, testset = mnist.load_data()\n",
    "\n",
    "train_images, train_labels = trainset\n",
    "test_images, test_labels = testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 5\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols*1.4, n_rows * 1.6))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        ax = plt.subplot(n_rows, n_cols, index + 1)\n",
    "        ax.set_title(train_labels[index])\n",
    "        ax.imshow(train_images[index], cmap=\"gray\")\n",
    "        plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARCFACE 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN 모형 구성하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "from functools import partial\n",
    "\n",
    "# Conv2D Default 세팅값 변경\n",
    "Conv2D = partial(Conv2D, kernel_size=(3,3), \n",
    "                 kernel_regularizer=l2(1e-4),\n",
    "                 activation='relu', padding='same')\n",
    "\n",
    "inputs = Input(shape=(28,28,1), name='images')\n",
    "\n",
    "conv = Conv2D(16, name='conv1_1')(inputs)\n",
    "conv = BatchNormalization(name='bn1_1')(conv)\n",
    "conv = Conv2D(16, name='conv1_2')(conv)\n",
    "conv = BatchNormalization(name='bn1_2')(conv)\n",
    "pool = MaxPooling2D(name='pool1')(conv)\n",
    "\n",
    "conv = Conv2D(32, name='conv2_1')(pool)\n",
    "conv = BatchNormalization(name='bn2_1')(conv)\n",
    "conv = Conv2D(32, name='conv2_2')(conv)\n",
    "conv = BatchNormalization(name='bn2_2')(conv)\n",
    "pool = MaxPooling2D(name='pool2')(conv)\n",
    "\n",
    "conv = Conv2D(64, name='conv3_1')(pool)\n",
    "conv = BatchNormalization(name='bn3_1')(conv)\n",
    "conv = Conv2D(64, name='conv3_2')(conv)\n",
    "conv = BatchNormalization(name='bn3_2')(conv)\n",
    "pool = MaxPooling2D(name='pool3')(conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 때 convolution의 출력을 `Flatten`을 통해 1차원으로 바꾸어 준 후, 유닛의 갯수가 3개인 `Dense`를 통과해 줍니다. 이를 통해 우리는 (28,28)의 이미지를 3개의 숫자로 표현하는 임베딩 모델을 구성하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "num_embed = 2\n",
    "\n",
    "x = BatchNormalization()(pool)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(num_embed, use_bias=False,\n",
    "          kernel_regularizer=l2(1e-4), name='embed')(x)\n",
    "x = BatchNormalization()(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARCFace Layer 구성하기\n",
    "\n",
    "\n",
    "![Imgur](https://i.imgur.com/lOFkd8W.png)\n",
    "\n",
    "$$\n",
    "softmax_{arcface} = -\\frac{1}{N}\\sum^{N}_{i=1} log \\frac{e^{s(cos(\\theta_{y_i}+m))}}{e^{s(cos(\\theta_{y_i} + m))+ \\sum_{j\\neq y_i} e^{s(cos(\\theta_{y_j}))}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 각 클래스 별 기준 Vector 구하기\n",
    "\n",
    "각 클래스 별로 기준 벡터를 둡니다. A 클래스에 해당하는 이미지의 임베딩 벡터는 A 기준 벡터와 유사하도록, B 클래스에 해당하는 이미지의 임베딩 벡터는 B 기준 벡터와 매우 유사하도록 학습할 예정입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "# 임의로 만들 기준 벡터\n",
    "weights = np.random.normal(0, 1., size=(num_embed, num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 두 벡터의 유사도를 계산하는 방법 : Cosine Similarity\n",
    "\n",
    "두 벡터의 유사성을 계산하는 방법에는 크게 거리를 기반한 방법과 각도를 기반한 방법이 존재합니다.<br>\n",
    "각도를 기반한 유사성을 구할 때에 주로 사용하는 것은 바로 `Cosine Similarity`입니다.\n",
    "\n",
    "\n",
    "$$\n",
    "similarity(A,B) = cos(\\theta) = \\frac{A\\cdot B}{|A| |B|}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return tf.matmul(a, b) / (\n",
    "        tf.linalg.norm(a, axis=1) * tf.linalg.norm(b, axis=0))\n",
    "\n",
    "cosine_similarity(x, weights.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 모델의 출력값은 총 10개가 나오는데, 이는 0부터 9까지의 라벨에 대한 유사도를 의미합니다.<br0>\n",
    "이미지의 임베딩 값이 $E_{image}$이고, 각 클래스에 대한 Weight 값은 $[W_{0}, W_{1}, W_{2}, \\cdots, W_{9}]$라고 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 보다 효과적으로 구별짓게 만드는 조건, Margin\n",
    "\n",
    "각 Class 별로 각도 차이가 크게 나는 방향으로 학습하도록, Margin 제약을 주게 됩니다. \n",
    "\n",
    "$$\n",
    "softmax_{arcface} = -\\frac{1}{N}\\sum^{N}_{i=1} log \\frac{e^{s(cos(\\theta_{y_i}+m))}}{e^{s(cos(\\theta_{y_i} + m))+ \\sum_{j\\neq y_i} e^{s(cos(\\theta_{y_j}))}}}\n",
    "$$\n",
    "\n",
    "이렇게 되면 어떻게 될까요? Margin이 0.5이라고 해봅시다. 모델이 완벽하게 학습이 되어서 타겟 클래스와의 유사도가 1로, $theta=0$이 되더라도, Margin이 붙기 때문에 유사도는 $cos(0+m) = cos(0.5)$가 됩니다.<br>\n",
    "그렇다면 다른 클래스와의 유사도(cos(0.5))보다 더 떨어져야지, 정확하게 분류할 수 있습니다.<br>\n",
    "이렇듯 Margin은 모델이 좀 더 완벽하게 구별하는 방향으로 강제합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - ArcFace 구성하기\n",
    "\n",
    "ArcFace는 기존 Softmax의 연산에 cosine Similarity와 Margin 연산만 추가하면 됩니다.<br>\n",
    "ArcFace는 scale와 margin에 매우 민감합니다. 해당 hyper-parameter들은 데이터의 상황에 따라 다르게 결정되어야 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow as tf\n",
    "\n",
    "class ArcFace(Layer):\n",
    "    def __init__(self, num_classes, \n",
    "                 scale=64, margin=0.5, **kwargs):\n",
    "        self.num_classes = num_classes\n",
    "        self.scale = scale\n",
    "        self.margin = margin\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            name='weight', trainable=True,\n",
    "            shape=(input_shape[0][-1], self.num_classes))\n",
    "        super().build(input_shape)\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        assert isinstance(inputs, list) or isinstance(inputs, tuple)\n",
    "        # Last Convolution Layers output and Ground Truth Label\n",
    "        features, labels = inputs\n",
    "        \n",
    "        # (1) 각 클래스 별로 코사인 유사도 구하기\n",
    "        norm_feat = tf.linalg.l2_normalize(features, axis=1)\n",
    "        norm_weight = tf.linalg.l2_normalize(self.w, axis=0)\n",
    "        cosine = norm_feat @ norm_weight\n",
    "        # 이미지와 특정 클래스와의 유사도가 높을수록 해당 값이 1에 가까워지고\n",
    "        # 낮을 수록 -1에 가까워짐\n",
    "        \n",
    "        # (2) acos을 통해 theta값 구하기\n",
    "        # acos란? cosine의 역함수.\n",
    "        # 주의할 점 : \n",
    "        # acos은 -1.~1.값 범위 외 input이 들어올 시 NaN 값 반환하기 때문에\n",
    "        # 값의 범위를 잡아주어야 함.\n",
    "        # acos의 출력값 0:~np.pi\n",
    "        cosine = tf.clip_by_value(cosine, -1.+1e-7, 1.-1e-7) \n",
    "        theta = tf.math.acos(cosine)\n",
    "        \n",
    "        # (3) GT Class에 해당하는 Theta에만 Margin을 부여\n",
    "        one_hot = tf.one_hot(labels, self.num_classes,\n",
    "                             True, False, axis=-1) \n",
    "        margin_theta = tf.where(one_hot, theta + self.margin, theta)\n",
    "        margin_theta = tf.clip_by_value(margin_theta, 0., np.pi)\n",
    "        \n",
    "        # (4) Cosine 값으로 복원 후, Scaling (보통 64)\n",
    "        logits = self.scale * tf.math.cos(margin_theta)\n",
    "        return logits\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"num_classes\": self.num_classes,\n",
    "            \"scale\": self.scale,\n",
    "            \"margin\": self.margin\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "scale = 30\n",
    "margin = 0.5\n",
    "\n",
    "# 해당 이미지가 어떤 클래스인지 알려줌으로써\n",
    "# 대상 클래스에 대한 Margin만 추가\n",
    "labels = Input(shape=(), dtype=tf.int32, name='labels')\n",
    "outputs = ArcFace(num_classes, scale, margin)([x, labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정리하면 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "model = Model([inputs, labels], outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 컴파일하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "\n",
    "optimizer = Adam()\n",
    "loss = SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = [SparseCategoricalAccuracy()]\n",
    "\n",
    "model.compile(optimizer, loss, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 파이프라인 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "traingen = ImageDataGenerator(rescale=1/255.)\n",
    "validgen = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "trainset = traingen.flow(\n",
    "    (train_images[...,None], train_labels), train_labels, batch_size=128)\n",
    "validset = validgen.flow(\n",
    "    (test_images[...,None], test_labels), test_labels, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(trainset, validation_data=validset, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 임베딩 시각화하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임베딩 결과를 반환하는 모델 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_model = Model(inputs, embed)\n",
    "\n",
    "infer_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지에 대한 임베딩 결과 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeds = infer_model.predict(test_images[...,None]/255.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 이미지 별로 임베딩 결과는 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, embedding_value in zip(test_images, test_embeds[:3]):\n",
    "    plt.title(str(embedding_value))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임베딩 분포도 시각화하기\n",
    "\n",
    "Softmax를 통해 임베딩 했을 때와는 매우 다른 형상을 띕니다. 같은 이미지끼리는 특정 각도를 기준으로 가까이 모여 있는 것을 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_embeds = (\n",
    "    test_embeds / np.linalg.norm(test_embeds,axis=1,keepdims=True))\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "for c in range(len(np.unique(test_labels))):\n",
    "    plt.scatter(norm_embeds[test_labels==c, 0], \n",
    "                norm_embeds[test_labels==c, 1],  \n",
    "                s=20,alpha=0.05, label=c)\n",
    "\n",
    "plt.legend(fontsize=20, \n",
    "           loc='center left', \n",
    "           bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
